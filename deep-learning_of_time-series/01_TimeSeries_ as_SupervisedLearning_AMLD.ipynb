{"cells":[{"cell_type":"markdown","source":["# **Part 3: Deep Learning for Time Series**"],"metadata":{"id":"0ljWQCIqpEVp"}},{"cell_type":"markdown","source":["\n","## Instructors: \n","\n","* Rockefeller\n","* Dr Yae Gaba\n","* Dr Colleen Farrelly\n","    \n","    \n","Time Series Applications, AMLD Africa, Morocco 2022. "],"metadata":{"id":"Ro-X7hjQpKgV"}},{"cell_type":"markdown","source":["At the end of this tutorial, you will know the basics of:\n","\n","*   Data preprocessing for time series forecasting\n","*   The concept of forward and backward pass when training RNNs\n","*   Customizing RNN and LSTM and learnable parameters \n","*   Process input sequences through the network (forward pass)\n","*   Propagate gradients back into the networkâ€™s parameters (Backward pass)\n","*   Update the weights of the network.\n","*   Performing a a simple update rule: `weight = weight - learning_rate * gradient`\n","\n","\n","\n","\n"],"metadata":{"id":"G_IFTgRJpQw4"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Lps6M4l31Y25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/AMLD_files\""],"metadata":{"id":"X2gZ3uvm1kG5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o7srQaFD1R_3"},"source":["# **Time Series as Supervised Learning**"]},{"cell_type":"markdown","metadata":{"id":"-BfA_FHR1R_4"},"source":["# 1. Introduction"]},{"cell_type":"markdown","metadata":{"id":"P50-EmIJ1R_4"},"source":["Time series forecasting can be framed as a supervised learning problem. This reframing of your\n","time series data allows you access to the suite of standard linear and nonlinear machine learning\n","algorithms on your problem. \n","\n","In this practical, you will discover how you can re-frame your time-series problem as a supervised learning problem for machine learning. After reading this notebook,\n","you will know:\n","\n","\n","1. What supervised learning is and how it is the foundation for all predictive modeling machine learning algorithms.\n","\n","\n","2. The sliding window method for framing a time series dataset and how to use it.\n","\n","\n","3. How to use the sliding window for multivariate data and multi-step forecasting.\n","\n","\n","Let's get started."]},{"cell_type":"markdown","metadata":{"id":"SjvDpSIu1R_5"},"source":["# 2. Supervised Machine Learning\n"]},{"cell_type":"markdown","metadata":{"id":"Zb3xpRhd1R_5"},"source":["The majority of practical machine learning uses supervised learning. Supervised learning is\n","where you have `input variables (X)` and an `output variable (y)` and you use an algorithm to\n","learn the mapping function from the input to the output.\n","\n","$$Y = f(X)$$\n"]},{"cell_type":"markdown","metadata":{"id":"lMSY0_LE1R_5"},"source":["The goal is to approximate the real underlying mapping so well that when you have new\n","input data $(X)$, you can predict the output variables $(y)$ for that data. Below is a contrived\n","example of a supervised learning dataset where each row is an observation comprised of one\n","input variable $(X)$ and one output variable to be predicted $(y)$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_BRSfQH1R_6"},"outputs":[],"source":["X, y\n","5, 0.9\n","4, 0.8\n","5, 1.0\n","3, 0.7\n","4, 0.9"]},{"cell_type":"markdown","metadata":{"id":"_EpUc8E91R_8"},"source":["It is called supervised learning because the process of an algorithm learning from the training\n","dataset can be thought of as a teacher supervising the learning process. We know the correct\n","answers; the algorithm iteratively makes predictions on the training data and is corrected by\n","making updates. "]},{"cell_type":"markdown","metadata":{"id":"dOLFBvcy1R_9"},"source":["Learning stops when the algorithm achieves an acceptable level of performance.\n","Supervised learning problems can be further grouped into regression and classification problems.\n","\n","\n","* **Classification:** A classification problem is when the output variable is a category, such\n","as red and blue or disease and no disease.\n","\n","\n","* **Regression:** A regression problem is when the output variable is a real value, such as\n","dollars or weight. The contrived example above is a regression problem."]},{"cell_type":"markdown","metadata":{"id":"guNPcHp21R_-"},"source":["# 3. Sliding Window"]},{"cell_type":"markdown","metadata":{"id":"XBjWoAca1R_-"},"source":["Time series data can be phrased as supervised learning. Given a sequence of numbers for a time\n","series dataset, we can restructure the data to look like a supervised learning problem. We can\n","do this by using previous time steps as input variables and use the next time step as the output\n","variable. Let's make this concrete with an example. Imagine we have a time series as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"bubephBd1R__"},"outputs":[],"source":["time, measure\n","1,    100\n","2,    110\n","3,    108\n","4,    115\n","5,    120"]},{"cell_type":"markdown","metadata":{"id":"fdAe6ZAY1R__"},"source":["We can restructure this time series dataset as a supervised learning problem by using the\n","value at the previous time step to predict the value at the next time-step. Re-organizing the\n","time series dataset this way, the data would look as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1FOuuhn1R__"},"outputs":[],"source":["X,    y\n","?,   100\n","100, 110\n","110, 108\n","108, 115\n","115, 120\n","120,  ?"]},{"cell_type":"markdown","metadata":{"id":"Kis9HUG21R__"},"source":["Take a look at the above transformed dataset and compare it to the original time series.\n","Here are some observations:\n","\n","* We can see that the previous time step is the input (X) and the next time step is the output (y) in our supervised learning problem.\n","\n","\n","* We can see that the order between the observations is preserved, and must continue to be preserved when using this dataset to train a supervised model.\n","\n","\n","* We can see that we have no previous value that we can use to predict the first value in the sequence. We will delete this row as we cannot use it."]},{"cell_type":"markdown","metadata":{"id":"TCCT5vUx1SAA"},"source":["We can also see that we do not have a known next value to predict for the last value in\n","the sequence. We may want to delete this value while training our supervised model also.\n","The use of prior time steps to predict the next time step is called the sliding window method.\n","For short, it may be called the window method in some literature. \n","\n","\n","In statistics and time series\n","analysis, this is called a **lag or lag method**. \n","\n","The number of previous time steps is called the\n","**window width or size of the lag**. This sliding window is the basis for how we can turn any time\n","series dataset into a supervised learning problem. From this simple example, we can notice a\n","few things:\n","\n","\n","1. We can see how this can work to turn a time series into either a regression or a classification\n","supervised learning problem for real-valued or labeled time series values.\n","\n","\n","2. We can see how once a time series dataset is prepared this way that any of the standard\n","linear and nonlinear machine learning algorithms may be applied, as long as the order of\n","the rows is preserved.\n","\n","\n","3. We can see how the width sliding window can be increased to include more previous time\n","steps.\n","\n","\n","4. We can see how the sliding window approach can be used on a time series that has more than one value, or so-called multivariate time series."]},{"cell_type":"markdown","metadata":{"id":"2BqioM021SAA"},"source":["# 4. Sliding Window With Multivariates"]},{"cell_type":"markdown","metadata":{"id":"ixKQ3RWd1SAA"},"source":["The number of observations recorded for a given time in a time series dataset matters. Traditionally, different names are used:\n","    \n","* Univariate Time Series: These are datasets where only a single variable is observed\n","at each time, such as temperature each hour. The example in the previous section is a\n","univariate time series dataset.\n","\n","\n","* Multivariate Time Series: These are datasets where two or more variables are observed\n","at each time.\n","\n","\n","Most time series analysis methods, and even books on the topic, focus on univariate data.\n","This is because it is the simplest to understand and work with. Multivariate data is often more\n","difficult to work with. It is harder to model and often many of the classical methods do not\n","perform well.\n","\n","\n","Multivariate time series analysis considers simultaneously multiple time series.\n","It is, in general, much more complicated than univariate time series analysis"]},{"cell_type":"markdown","metadata":{"id":"f98qZZgJ1SAA"},"source":["The sweet spot for using machine learning for time series is where classical methods fall\n","down. This may be with complex univariate time series, and is more likely with multivariate\n","time series given the additional complexity. Below is another worked example to make the\n","sliding window method concrete for multivariate time series. Assume we have the contrived\n","multivariate time series dataset below with two observations at each time step. Let's also assume\n","that we are only concerned with predicting **measure2.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w36vx74b1SAB"},"outputs":[],"source":["time, measure1, measure2\n","1,      0.2,      88\n","2,      0.5,      89\n","3,      0.7,      87\n","4,      0.4,      88\n","5,      1.0,      90"]},{"cell_type":"markdown","metadata":{"id":"C-8hapFn1SAB"},"source":["We can reframe this time series dataset as a supervised learning problem with a window\n","width of one. This means that we will use the previous time step values of `measure1` and\n","`measure2`. We will also have available the next time step value for measure1. We will then\n","predict the next time step value of **measure2.** This will give us 3 input features and one output\n","value to predict for each training pattern."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_42DF3oj1SAB"},"outputs":[],"source":["X1,    X2,    X3,      y\n","?,      ?,    0.2,    88\n","0.2,    88,   0.5,    89\n","0.5,    89,   0.7,    87\n","0.7,    87,   0.4,    88\n","0.4,    88,   1.0,    90\n","1.0,    90,    ?,      ?"]},{"cell_type":"markdown","metadata":{"id":"65uDgb171SAB"},"source":["We can see that as in the univariate time series example above, we may need to remove the\n","first and last rows in order to train our supervised learning model. This example raises the\n","question of what if we wanted to predict both measure1 and measure2 for the next time step?\n","\n","\n","The sliding window approach can also be used in this case. Using the same time series dataset\n","above, we can phrase it as a supervised learning problem where we predict both `measure1` and\n","`measure2` with the same window width of one, as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QG2KfP4V1SAC"},"outputs":[],"source":["X1,    X2,    y1,    y2\n","?,     ?,     0.2,   88\n","0.2,   88,    0.5,   89\n","0.5,   89,    0.7,   87\n","0.7,   87,    0.4,   88\n","0.4,   88,    1.0,   90\n","1.0,   90,    ?,     ?"]},{"cell_type":"markdown","metadata":{"id":"p_DXQMOQ1SAC"},"source":["Not many supervised learning methods can handle the prediction of multiple output values\n","without modification, but some methods, like artificial neural networks, have little trouble. **We\n","can think of predicting more than one value as predicting a sequence.** In this case, we were\n","predicting two different output variables, but we may want to predict multiple time-steps ahead\n","of one output variable. This is called multi-step forecasting."]},{"cell_type":"markdown","metadata":{"id":"SjEx2QrZ1SAC"},"source":["# 5.  Sliding Window With Multiple Steps"]},{"cell_type":"markdown","metadata":{"id":"4T9I-6pe1SAC"},"source":["The number of time steps ahead to be forecasted is important. Again, it is traditional to use\n","different names for the problem depending on the number of time-steps to forecast:\n","    \n","* One-step Forecast: This is where the next time step (t+1) is predicted.\n","* Multi-step Forecast: This is where two or more future time steps are to be predicted.\n","\n","\n","\n","All of the examples we have looked at so far have been one-step forecasts. There are a\n","number of ways to model multi-step forecasting as a supervised learning problem. For now,\n","we are focusing on framing multi-step forecast using the sliding window method. Consider the\n","same univariate time series dataset from the first sliding window example above:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNDnGc0h1SAD"},"outputs":[],"source":["time, measure\n","1,    100\n","2,    110\n","3,    108\n","4,    115\n","5,    120"]},{"cell_type":"markdown","metadata":{"id":"C6ShK7661SAD"},"source":["We can frame this time series as a two-step forecasting dataset for supervised learning with\n","a window width of one, as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpQcC_Dy1SAD"},"outputs":[],"source":["X1,     y1,    y2\n","?  ,    100,   110\n","100,    110,   108\n","110,    108,   115\n","108,    115,   120\n","115,    120,    ?\n","120,     ?,     ? "]},{"cell_type":"markdown","metadata":{"id":"zSsgy-Kp1SAD"},"source":["We can see that the first row and the last two rows cannot be used to train a supervised\n","model. It is also a good example to show the burden on the input variables. Specifically, that\n","a supervised model only has X1 to work with in order to predict both y1 and y2. Careful\n","thought and experimentation are needed on your problem to find a window width that results\n","in acceptable model performance."]},{"cell_type":"markdown","metadata":{"id":"hHdIBMxS1SAD"},"source":["The end"]},{"cell_type":"markdown","metadata":{"id":"-uGHY46I1SAE"},"source":["# References:\n","\n","1. Brownlee, Jason. Deep learning for time series forecasting: predict the future with MLPs, CNNs and LSTMs in Python. Machine Learning Mastery, 2018.\n","2. Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.\n","3. Deep Learning for Time Series Forecasting, yijingchen https://github.com/Azure/DeepLearningForTimeSeriesForecasting"]},{"cell_type":"markdown","source":["The end! "],"metadata":{"id":"d_GE9_dEtcs2"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}